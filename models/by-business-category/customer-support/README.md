# 顧客サポート／FAQ 自動応答での LLM 活用ガイド

## 📋 業務概要
- **カテゴリ名**: 顧客サポート／FAQ 自動応答
- **主要タスク**: チャットボット、メール一次回答、問い合わせ分類
- **重視指標**: 正確性・低レイテンシ・コスト
- **自動化対象**: 1次対応、FAQ案内、エスカレーション判定

## 🎯 推奨モデル

### Tier 1: 最高性能（高コスト）
| モデル | 評価 | 月額コスト目安 | 特徴 |
|-------|------|---------------|------|
| OpenAI: gpt-oss-120b | 4.5/5 | $300-800 | 高精度、複雑問い合わせ対応 |
| Google: Gemini 2.5 Pro | 4.4/5 | $400-1000 | マルチモーダル対応 |
| Anthropic: Claude Opus 4.1 | 4.3/5 | $600-1500 | 安全性重視、詳細回答 |

### Tier 2: バランス型（中コスト）
| モデル | 評価 | 月額コスト目安 | 特徴 |
|-------|------|---------------|------|
| Google: Gemini 2.5 Flash | 4.1/5 | $150-400 | 高速応答、コスパ良 |
| Qwen: Qwen3 30B A3B | 4.0/5 | $120-300 | 多言語対応、エージェント機能 |
| xAI: Grok 3 | 3.9/5 | $200-500 | リアルタイム情報対応 |

### Tier 3: コスト重視（低コスト・無料）
| モデル | 評価 | 月額コスト目安 | 特徴 |
|-------|------|---------------|------|
| OpenAI: gpt-oss-20b (free) | 3.8/5 | 無料 | 基本的な問い合わせ対応 |
| DeepSeek: R1 0528 (free) | 3.7/5 | 無料 | 推論能力高、無料 |
| Mistral: Small 3.2 24B (free) | 3.5/5 | 無料 | 軽量、高速 |

## 🏢 日本企業での活用事例

### 事例1: 大手ECサイト
- **業界**: Eコマース
- **企業規模**: 従業員1000名以上
- **使用モデル**: OpenAI gpt-oss-120b
- **導入前の課題**: 月間10万件の問い合わせ、平均回答時間24時間
- **導入後の効果**: 1次回答率80%、平均回答時間2分に短縮
- **ROI**: 月間人件費300万円削減
- **導入期間**: 3ヶ月

### 事例2: 地方銀行
- **業界**: 金融
- **企業規模**: 従業員500名
- **使用モデル**: Google Gemini 2.5 Flash
- **導入前の課題**: 電話問い合わせの90%が定型質問
- **導入後の効果**: 定型問い合わせの自動化率95%
- **ROI**: 月間150万円のコスト削減
- **導入期間**: 2ヶ月

### 事例3: SaaSスタートアップ
- **業界**: IT・ソフトウェア
- **企業規模**: 従業員50名
- **使用モデル**: DeepSeek R1 0528 (free)
- **導入前の課題**: 限られたCS人員で24時間対応が困難
- **導入後の効果**: 夜間・休日の自動対応を実現
- **ROI**: 追加人員雇用コスト月60万円を回避
- **導入期間**: 1ヶ月

## 💡 実装パターン

### パターン1: FAQ自動回答システム
**適用場面**: 定型的な問い合わせが多い場合
**推奨モデル**: OpenAI gpt-oss-120b, Gemini 2.5 Flash
**実装例**:
```python
import openai
from vector_db import search_faq

def auto_respond_faq(query):
    # FAQ検索
    relevant_faqs = search_faq(query, top_k=3)
    
    # LLMで回答生成
    prompt = f"""
    以下のFAQを参考に、お客様の質問に丁寧に回答してください。
    
    質問: {query}
    関連FAQ: {relevant_faqs}
    
    回答は以下の形式で作成してください：
    - 親しみやすく、丁寧な敬語
    - 必要に応じて詳細な手順を含める
    - 解決しない場合の次のステップを明示
    """
    
    response = openai.chat.completions.create(
        model="gpt-oss-120b",
        messages=[{"role": "user", "content": prompt}]
    )
    
    return response.choices[0].message.content
```
**プロンプト例**:
```
あなたは親切で知識豊富なカスタマーサポート担当者です。
以下のガイドラインに従って回答してください：

1. 丁寧で親しみやすい敬語を使用
2. 回答は簡潔かつ具体的に
3. 不明点がある場合は追加情報を求める
4. 解決できない場合は適切な担当者への転送を提案

質問: {customer_query}
関連情報: {context}
```

### パターン2: 問い合わせ分類・優先度付け
**適用場面**: 大量の問い合わせを効率的に振り分けたい場合
**推奨モデル**: Gemini 2.5 Flash, Qwen3 30B
**実装例**:
```python
def classify_inquiry(inquiry_text):
    prompt = f"""
    以下の問い合わせ内容を分析し、以下の形式でJSONで返してください：
    
    {{
        "category": "技術的問題 | 料金・請求 | アカウント | 返品・交換 | その他",
        "priority": "高 | 中 | 低",
        "sentiment": "ポジティブ | ニュートラル | ネガティブ",
        "estimated_resolution_time": "即座 | 1時間以内 | 1日以内 | 要相談",
        "required_department": "CS | 技術 | 経理 | 法務",
        "auto_respondable": true/false
    }}
    
    問い合わせ内容: {inquiry_text}
    """
    
    # 分類結果を取得
    # 実装詳細...
```

### パターン3: リアルタイムチャットボット
**適用場面**: Webサイトやアプリでのリアルタイム対応
**推奨モデル**: Gemini 2.5 Flash, OpenAI gpt-oss-20b (free)
**実装例**:
```python
class ChatBot:
    def __init__(self, model="gemini-2.5-flash"):
        self.model = model
        self.conversation_history = []
    
    def respond(self, user_message):
        self.conversation_history.append({"role": "user", "content": user_message})
        
        # システムプロンプト設定
        system_prompt = """
        あなたは当社のカスタマーサポートチャットボットです。
        - 迅速で正確な回答を心がけてください
        - わからない場合は正直に伝え、人間のオペレーターに繋ぎます
        - 常に親切で丁寧な対応を心がけてください
        """
        
        messages = [{"role": "system", "content": system_prompt}] + self.conversation_history
        
        # API呼び出し（実装詳細は省略）
        response = self.call_llm_api(messages)
        
        self.conversation_history.append({"role": "assistant", "content": response})
        
        return response
```

## 📊 コスト分析

### 月間処理量別コスト試算
| 処理量/月 | Tier 1 | Tier 2 | Tier 3 |
|----------|--------|--------|--------|
| 1万件 | $80-200 | $30-80 | $0-10 |
| 10万件 | $800-2000 | $300-800 | $0-100 |
| 100万件 | $8000-20000 | $3000-8000 | $0-1000 |

### ROI計算例（月間10万件処理の場合）
- **人件費削減**: CS担当者3名分 = 月120万円
- **時間短縮効果**: 顧客待機時間削減による満足度向上 = 月30万円相当
- **品質向上効果**: 24時間対応による機会損失回避 = 月50万円相当
- **システムコスト**: Tier 2モデル利用 = 月10万円
- **Net ROI**: 月190万円の効果

## ⚠️ 導入時の注意点

### 技術的な課題
- 既存のCRMシステムとの連携設計が必要
- 回答精度の継続的な改善・学習システムの構築
- レスポンス時間とコストのバランス調整

### 運用上の課題
- 人間のオペレーターとのエスカレーション基準の明確化
- ブランドトーンに合わせたカスタマイズが必要
- 継続的な品質監視・改善体制の確立

### 法的・コンプライアンス課題
- 個人情報保護法に準拠したデータ処理
- 金融・医療等の規制業界での利用制限に注意
- 誤回答時の責任体制の明確化

## 🚀 導入ロードマップ

### Phase 1: 検証（1-2ヶ月）
1. 既存の問い合わせデータ分析・カテゴライズ
2. POC環境での複数モデル比較テスト
3. 回答精度とコスト効果の測定

### Phase 2: 部分導入（2-3ヶ月）
1. 定型的な問い合わせカテゴリから段階導入
2. 人間オペレーターとの併用体制確立
3. エスカレーション基準・フローの整備

### Phase 3: 本格運用（3-6ヶ月）
1. 全カテゴリへの拡大適用
2. 継続的な学習・改善システムの構築
3. KPI監視・レポーティング体制の確立

## 📚 関連リソース
- [実装ガイド詳細](implementation-patterns/README.md)
- [プロンプトテンプレート集](../../../templates/customer-support-prompts.md)
- [コストカルキュレーター](../../../tools/cost-calculator.html)
- [コミュニティフォーラム](https://github.com/kimurataiyou/all-model-list/discussions)

---

**最終更新**: 2025-08-07  
**情報提供**: コミュニティ貢献  
**次回更新予定**: 2025-09-07